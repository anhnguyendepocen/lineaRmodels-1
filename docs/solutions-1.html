<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>2.6 Solutions | lineaRmodels</title>
  <meta name="description" content="This is a web complement to MATH 341 (Linear Models), a first regression course for EPFL mathematicians.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="2.6 Solutions | lineaRmodels />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a web complement to MATH 341 (Linear Models), a first regression course for EPFL mathematicians." />
  <meta name="github-repo" content="lbelzile/lineaRmodels" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.6 Solutions | lineaRmodels />
  
  <meta name="twitter:description" content="This is a web complement to MATH 341 (Linear Models), a first regression course for EPFL mathematicians." />
  

<meta name="author" content="Léo Belzile">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="summary-of-week-2.html">
<link rel="next" href="frischwaughlovell-theorem.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="libs/rglwidgetClass-2/rgl.css" rel="stylesheet" />
<script src="libs/rglwidgetClass-2/rglClass.src.js"></script>
<script src="libs/CanvasMatrix4-2016/CanvasMatrix.src.js"></script>
<script src="libs/rglWebGL-binding-0.100.1/rglWebGL.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Linear Models</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preliminary remarks</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="basics-of-r.html"><a href="basics-of-r.html"><i class="fa fa-check"></i><b>1.1</b> Basics of <strong>R</strong></a><ul>
<li class="chapter" data-level="1.1.1" data-path="basics-of-r.html"><a href="basics-of-r.html#help"><i class="fa fa-check"></i><b>1.1.1</b> Help</a></li>
<li class="chapter" data-level="1.1.2" data-path="basics-of-r.html"><a href="basics-of-r.html#basic-commands"><i class="fa fa-check"></i><b>1.1.2</b> Basic commands</a></li>
<li class="chapter" data-level="1.1.3" data-path="basics-of-r.html"><a href="basics-of-r.html#linear-algebra-in-r"><i class="fa fa-check"></i><b>1.1.3</b> Linear algebra in <strong>R</strong></a></li>
<li class="chapter" data-level="1.1.4" data-path="basics-of-r.html"><a href="basics-of-r.html#packages"><i class="fa fa-check"></i><b>1.1.4</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="week1.html"><a href="week1.html"><i class="fa fa-check"></i><b>1.2</b> Tutorial 1</a><ul>
<li class="chapter" data-level="1.2.1" data-path="week1.html"><a href="week1.html#datasets"><i class="fa fa-check"></i><b>1.2.1</b> Datasets</a></li>
<li class="chapter" data-level="1.2.2" data-path="week1.html"><a href="week1.html#graphics"><i class="fa fa-check"></i><b>1.2.2</b> Graphics</a></li>
<li class="chapter" data-level="1.2.3" data-path="week1.html"><a href="week1.html#projection-matrices"><i class="fa fa-check"></i><b>1.2.3</b> Projection matrices</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>1.3</b> Exercises</a><ul>
<li class="chapter" data-level="1.3.1" data-path="exercises.html"><a href="exercises.html#auto-dataset"><i class="fa fa-check"></i><b>1.3.1</b> Auto dataset</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="solutions.html"><a href="solutions.html"><i class="fa fa-check"></i><b>1.4</b> Solutions</a><ul>
<li class="chapter" data-level="1.4.1" data-path="solutions.html"><a href="solutions.html#exercise-1.4---oblique-projections"><i class="fa fa-check"></i><b>1.4.1</b> Exercise 1.4 - Oblique projections</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="summary-of-week-1.html"><a href="summary-of-week-1.html"><i class="fa fa-check"></i><b>1.5</b> Summary of week 1</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="computational-considerations.html"><a href="computational-considerations.html"><i class="fa fa-check"></i><b>2</b> Computational considerations</a><ul>
<li class="chapter" data-level="2.1" data-path="calculation-of-least-square-estimates.html"><a href="calculation-of-least-square-estimates.html"><i class="fa fa-check"></i><b>2.1</b> Calculation of least square estimates</a><ul>
<li class="chapter" data-level="2.1.1" data-path="calculation-of-least-square-estimates.html"><a href="calculation-of-least-square-estimates.html#interpretation-of-the-coefficients"><i class="fa fa-check"></i><b>2.1.1</b> Interpretation of the coefficients</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="the-lm-function.html"><a href="the-lm-function.html"><i class="fa fa-check"></i><b>2.2</b> The <code>lm</code> function</a><ul>
<li class="chapter" data-level="2.2.1" data-path="the-lm-function.html"><a href="the-lm-function.html#singular-value-decomposition"><i class="fa fa-check"></i><b>2.2.1</b> Singular value decomposition</a></li>
<li class="chapter" data-level="2.2.2" data-path="the-lm-function.html"><a href="the-lm-function.html#qr-decomposition"><i class="fa fa-check"></i><b>2.2.2</b> QR decomposition</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="the-hyperplane-of-fitted-values.html"><a href="the-hyperplane-of-fitted-values.html"><i class="fa fa-check"></i><b>2.3</b> The hyperplane of fitted values</a></li>
<li class="chapter" data-level="2.4" data-path="centered-coefficient-of-determination.html"><a href="centered-coefficient-of-determination.html"><i class="fa fa-check"></i><b>2.4</b> (Centered) coefficient of determination</a></li>
<li class="chapter" data-level="2.5" data-path="summary-of-week-2.html"><a href="summary-of-week-2.html"><i class="fa fa-check"></i><b>2.5</b> Summary of week 2</a></li>
<li class="chapter" data-level="2.6" data-path="solutions-1.html"><a href="solutions-1.html"><i class="fa fa-check"></i><b>2.6</b> Solutions</a><ul>
<li class="chapter" data-level="2.6.1" data-path="solutions-1.html"><a href="solutions-1.html#exercise-3.5---prostate-cancer"><i class="fa fa-check"></i><b>2.6.1</b> Exercise 3.5 - Prostate cancer</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="frischwaughlovell-theorem.html"><a href="frischwaughlovell-theorem.html"><i class="fa fa-check"></i><b>3</b> Frisch–Waugh–Lovell theorem</a><ul>
<li class="chapter" data-level="3.1" data-path="revisiting-the-interpretation-of-the-parameters-of-a-linear-model.html"><a href="revisiting-the-interpretation-of-the-parameters-of-a-linear-model.html"><i class="fa fa-check"></i><b>3.1</b> Revisiting the interpretation of the parameters of a linear model</a></li>
<li class="chapter" data-level="3.2" data-path="factors.html"><a href="factors.html"><i class="fa fa-check"></i><b>3.2</b> Factors</a></li>
<li class="chapter" data-level="3.3" data-path="example-seasonal-effects.html"><a href="example-seasonal-effects.html"><i class="fa fa-check"></i><b>3.3</b> Example: seasonal effects</a></li>
<li class="chapter" data-level="3.4" data-path="solutions-2.html"><a href="solutions-2.html"><i class="fa fa-check"></i><b>3.4</b> Solutions</a><ul>
<li class="chapter" data-level="3.4.1" data-path="solutions-2.html"><a href="solutions-2.html#exercise-4.4"><i class="fa fa-check"></i><b>3.4.1</b> Exercise 4.4</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="gaussian-linear-model.html"><a href="gaussian-linear-model.html"><i class="fa fa-check"></i><b>4</b> Gaussian linear model</a><ul>
<li class="chapter" data-level="4.1" data-path="confidence-and-prediction-intervals.html"><a href="confidence-and-prediction-intervals.html"><i class="fa fa-check"></i><b>4.1</b> Confidence and prediction intervals</a></li>
<li class="chapter" data-level="4.2" data-path="residuals.html"><a href="residuals.html"><i class="fa fa-check"></i><b>4.2</b> Residuals</a></li>
<li class="chapter" data-level="4.3" data-path="diagnostic-plots.html"><a href="diagnostic-plots.html"><i class="fa fa-check"></i><b>4.3</b> Diagnostic plots</a><ul>
<li class="chapter" data-level="4.3.1" data-path="diagnostic-plots.html"><a href="diagnostic-plots.html#added-variable-plots"><i class="fa fa-check"></i><b>4.3.1</b> Added-variable plots</a></li>
<li class="chapter" data-level="4.3.2" data-path="diagnostic-plots.html"><a href="diagnostic-plots.html#diagnostic-of-heteroscedasticity"><i class="fa fa-check"></i><b>4.3.2</b> Diagnostic of heteroscedasticity</a></li>
<li class="chapter" data-level="4.3.3" data-path="diagnostic-plots.html"><a href="diagnostic-plots.html#outliers"><i class="fa fa-check"></i><b>4.3.3</b> Outliers</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="qqplot.html"><a href="qqplot.html"><i class="fa fa-check"></i><b>4.4</b> Quantile-quantile plots</a><ul>
<li class="chapter" data-level="4.4.1" data-path="qqplot.html"><a href="qqplot.html#quantile-quantile-plot-of-externally-studentized-errors"><i class="fa fa-check"></i><b>4.4.1</b> Quantile-quantile plot of externally studentized errors</a></li>
<li class="chapter" data-level="4.4.2" data-path="qqplot.html"><a href="qqplot.html#quantile-quantile-plot-using-the-qr-decomposition"><i class="fa fa-check"></i><b>4.4.2</b> Quantile-quantile plot using the QR decomposition</a></li>
<li class="chapter" data-level="4.4.3" data-path="qqplot.html"><a href="qqplot.html#monte-carlo-methods-for-confidence-intervals"><i class="fa fa-check"></i><b>4.4.3</b> Monte Carlo methods for confidence intervals</a></li>
<li class="chapter" data-level="4.4.4" data-path="qqplot.html"><a href="qqplot.html#parametric-bootstrap-confidence-intervals-using-the-qr-decomposition"><i class="fa fa-check"></i><b>4.4.4</b> Parametric bootstrap confidence intervals using the QR decomposition</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="solutions-3.html"><a href="solutions-3.html"><i class="fa fa-check"></i><b>4.5</b> Solutions</a><ul>
<li class="chapter" data-level="4.5.1" data-path="solutions-3.html"><a href="solutions-3.html#exercise-7.1---study-of-growth-hormones"><i class="fa fa-check"></i><b>4.5.1</b> Exercise 7.1 - Study of growth hormones</a></li>
<li class="chapter" data-level="4.5.2" data-path="solutions-3.html"><a href="solutions-3.html#exercise-7.2---electric-production-of-windmills"><i class="fa fa-check"></i><b>4.5.2</b> Exercise 7.2 - Electric production of windmills</a></li>
<li class="chapter" data-level="4.5.3" data-path="solutions-3.html"><a href="solutions-3.html#exercise-7.3---air-traffic"><i class="fa fa-check"></i><b>4.5.3</b> Exercise 7.3 - Air traffic</a></li>
<li class="chapter" data-level="4.5.4" data-path="solutions-3.html"><a href="solutions-3.html#exercise-7.4---determinants-of-earnings"><i class="fa fa-check"></i><b>4.5.4</b> Exercise 7.4 - Determinants of earnings</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html"><i class="fa fa-check"></i><b>5</b> Analysis of variance</a><ul>
<li class="chapter" data-level="5.1" data-path="sum-of-squares-decomposition.html"><a href="sum-of-squares-decomposition.html"><i class="fa fa-check"></i><b>5.1</b> Sum of squares decomposition</a><ul>
<li class="chapter" data-level="5.1.1" data-path="sum-of-squares-decomposition.html"><a href="sum-of-squares-decomposition.html#the-decomposition-of-squares-in-r"><i class="fa fa-check"></i><b>5.1.1</b> The decomposition of squares in <strong>R</strong></a></li>
<li class="chapter" data-level="5.1.2" data-path="sum-of-squares-decomposition.html"><a href="sum-of-squares-decomposition.html#dropping-or-adding-variables"><i class="fa fa-check"></i><b>5.1.2</b> Dropping or adding variables</a></li>
<li class="chapter" data-level="5.1.3" data-path="sum-of-squares-decomposition.html"><a href="sum-of-squares-decomposition.html#biased-rss"><i class="fa fa-check"></i><b>5.1.3</b> Biased estimators of the residual sum of square</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="one-way-anova.html"><a href="one-way-anova.html"><i class="fa fa-check"></i><b>5.2</b> One-way ANOVA</a></li>
<li class="chapter" data-level="5.3" data-path="two-way-anova-and-irrelevant-hypotheses.html"><a href="two-way-anova-and-irrelevant-hypotheses.html"><i class="fa fa-check"></i><b>5.3</b> Two-way ANOVA and irrelevant hypotheses</a></li>
<li class="chapter" data-level="5.4" data-path="solutions-4.html"><a href="solutions-4.html"><i class="fa fa-check"></i><b>5.4</b> Solutions</a><ul>
<li class="chapter" data-level="5.4.1" data-path="solutions-4.html"><a href="solutions-4.html#exercise-9.3---one-way-analysis-of-variance"><i class="fa fa-check"></i><b>5.4.1</b> Exercise 9.3 - One-way analysis of variance</a></li>
<li class="chapter" data-level="5.4.2" data-path="solutions-4.html"><a href="solutions-4.html#exercise-9.4---two-way-analysis-of-variance"><i class="fa fa-check"></i><b>5.4.2</b> Exercise 9.4 - Two-way analysis of variance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>6</b> Hypothesis testing</a></li>
<li class="chapter" data-level="7" data-path="model-selection.html"><a href="model-selection.html"><i class="fa fa-check"></i><b>7</b> Model selection</a><ul>
<li class="chapter" data-level="7.1" data-path="example-price-of-diamonds.html"><a href="example-price-of-diamonds.html"><i class="fa fa-check"></i><b>7.1</b> Example: Price of diamonds</a><ul>
<li class="chapter" data-level="7.1.1" data-path="example-price-of-diamonds.html"><a href="example-price-of-diamonds.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>7.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="7.1.2" data-path="example-price-of-diamonds.html"><a href="example-price-of-diamonds.html#model-selection-1"><i class="fa fa-check"></i><b>7.1.2</b> Model selection</a></li>
<li class="chapter" data-level="7.1.3" data-path="example-price-of-diamonds.html"><a href="example-price-of-diamonds.html#information-criterion"><i class="fa fa-check"></i><b>7.1.3</b> Information criterion</a></li>
<li class="chapter" data-level="7.1.4" data-path="example-price-of-diamonds.html"><a href="example-price-of-diamonds.html#cross-validation"><i class="fa fa-check"></i><b>7.1.4</b> Cross-validation</a></li>
<li class="chapter" data-level="7.1.5" data-path="example-price-of-diamonds.html"><a href="example-price-of-diamonds.html#presentation-of-results"><i class="fa fa-check"></i><b>7.1.5</b> Presentation of results</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="model-selection-invalidates-p-values.html"><a href="model-selection-invalidates-p-values.html"><i class="fa fa-check"></i><b>7.2</b> Model selection invalidates P-values</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="penalized-regression-methods.html"><a href="penalized-regression-methods.html"><i class="fa fa-check"></i><b>8</b> Penalized regression methods</a><ul>
<li class="chapter" data-level="8.1" data-path="bias-and-variance-tradeoff.html"><a href="bias-and-variance-tradeoff.html"><i class="fa fa-check"></i><b>8.1</b> Bias and variance tradeoff</a></li>
<li class="chapter" data-level="8.2" data-path="cross-validation-1.html"><a href="cross-validation-1.html"><i class="fa fa-check"></i><b>8.2</b> Cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>9</b> Splines</a><ul>
<li class="chapter" data-level="9.1" data-path="solutions-5.html"><a href="solutions-5.html"><i class="fa fa-check"></i><b>9.1</b> Solutions</a><ul>
<li class="chapter" data-level="9.1.1" data-path="solutions-5.html"><a href="solutions-5.html#exercise-12.4-smoothing-splines"><i class="fa fa-check"></i><b>9.1.1</b> Exercise 12.4 Smoothing splines</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>10</b> Generalized linear models</a><ul>
<li class="chapter" data-level="10.1" data-path="diagnostics-for-bernoulli-data.html"><a href="diagnostics-for-bernoulli-data.html"><i class="fa fa-check"></i><b>10.1</b> Diagnostics for Bernoulli data</a></li>
<li class="chapter" data-level="10.2" data-path="poisson-model-for-contingency-table.html"><a href="poisson-model-for-contingency-table.html"><i class="fa fa-check"></i><b>10.2</b> Poisson model for contingency table</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">lineaRmodels</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="solutions-1" class="section level2">
<h2><span class="header-section-number">2.6</span> Solutions</h2>
<p>The following questions refer to the dataset <code>prostate</code> from the package <code>ElemStatLearn</code>.</p>
<ol style="list-style-type: lower-alpha">
<li>Briefly describe the dataset.</li>
<li>Look at summaries of <code>lbph</code>. What likely value was imputed in places of zeros in `lbph} (before taking the logarithm)?</li>
<li>Produce a plot of the pair of variables <code>lcavol</code> and <code>lpsa</code> on the log and on the original scale. Comment on the relationship between <code>lcavol</code> and <code>lpsa</code>.</li>
<li>Fit a linear model using the log cancer volume as response variable, including a constant and the log prostate specific antigen as covariates. Obtain numerically the OLS estimates <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> of the parameters, the fitted values <span class="math inline">\(\hat{\boldsymbol{y}}\)</span> and the residuals <span class="math inline">\(\boldsymbol{e}\)</span> using the formulas given in class.</li>
<li>Compare the quantities you obtained with the output of the function <code>lm</code>.</li>
<li>Add the fitted regression line to the scatterplot of <code>lcavol</code> against <code>lpsa</code>.</li>
<li>Interpret the changes in cancer volume (not the log cancer volume), including any units in your interpretations.</li>
<li>Obtain the orthogonal projection matrix <span class="math inline">\(\mathbf{H}_\mathbf{X}\)</span> and the OLS coefficients <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> using a SVD decomposition of <span class="math inline">\(\mathbf{X}\)</span> (<code>svd</code>).</li>
<li>Compute the <span class="math inline">\(R^2_c\)</span> coefficient and compare with the one in <code>summary</code> output of the <code>lm</code> function. What can you say about the explanatory power of the covariate <code>lpsa</code>?</li>
</ol>
<div id="exercise-3.5---prostate-cancer" class="section level3">
<h3><span class="header-section-number">2.6.1</span> Exercise 3.5 - Prostate cancer</h3>
<p>The following questions refer to the dataset <code>prostate</code> from the package <code>ElemStatLearn</code>.</p>
<ol style="list-style-type: lower-alpha">
<li>Briefly describe the data set.</li>
</ol>
<p>Running <code>?ElemStatLearn::prostate</code> gives the help file for the data set. Since we will be coming back to this example, detailed informations are provided below.</p>
<p>This data set was extracted from</p>
<blockquote>
<p>Stamey, T.A., Kabalin, J.N., McNeal, J.E., Johnstone, I.M., Freiha, F., Redwine, E.A. and Yang, N. (1989)
Prostate specific antigen in the diagnosis and treatment of adenocarcinoma of the prostate: II. radical prostatectomy treated
patients, Journal of Urology 141(5), 1076–1083.</p>
</blockquote>
<p>This data set is described in Wakefield (2013), pp. 5-6.</p>
<blockquote>
<p>The data were collected on <span class="math inline">\(n=97\)</span> men before radical prostatectomy, a major surgical operation that
removes the entire prostate gland along with some surrounding tissue.</p>
</blockquote>
<blockquote>
<p>In Stamey et al. (1989), prostate specific antigen
(PSA) was proposed as a preoperative marker to predict the clinical stage of cancer. As well as modeling the stage of cancer as a
function of PSA, the authors also examined PSA as a function of age and seven other histological and morphometric covariates.</p>
</blockquote>
<blockquote>
<p>The BPH and capsular penetration variables originally contained zeros, and a small number was substituted before the log transform was taken. It is not clear from the original paper why the log transform was taken though PSA varies over a wide range, and so linearity
of the mean model may be aided by the log transform. It is also not clear why the variable PGS45 was constructed.</p>
</blockquote>
<p>The data set contains the following variables:</p>
<ul>
<li><code>lcavol</code>: log of cancer volume, measured in milliliters (cc). The area of cancer was measured from digitized images and
multiplied by a thickness to produce a volume.</li>
<li><code>lweight</code>: log of the prostate weight, measured in grams.</li>
<li><code>age</code>: The age of the patient, in years.</li>
<li><code>lbph</code>: log of the amount of benign prostatic hyperplasia (BPH), a noncancerous enlargement of the prostate gland, as
an area in a digitized image and reported in cm<span class="math inline">\({}^2\)</span>.</li>
<li><code>svi</code>: seminal vesicle invasion, a 0/1 indicator of whether prostate cancer cells have invaded the seminal vesicle.</li>
<li><code>lcp</code>: log of the capsular penetration, which represents the level of extension of cancer into the capsule (the fibrous
tissue which acts as an outer lining of the prostate gland), measured as the linear extent of penetration, in cm.</li>
<li><code>gleason</code>: Gleason score, a measure of the degree of aggressiveness of the tumor. The Gleason grading system assigns a
grade (1–5) to each of the two largest areas of cancer in the tissue samples with 1 being the least aggressive and 5 the most
aggressive; the two grades are then added together to produce the Gleason score.</li>
<li><code>pgg45</code>: percentage of Gleason scores that are 4 or 5.</li>
<li><code>lpsa</code>: log of prostate specific antigen (PSA), a concentration measured in ng/m</li>
</ul>
<p>To load the data set, use</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Install package if you get an error message</span>
<span class="co">#install.packages(&quot;ElemStatLearn&quot;)</span>
<span class="kw">data</span>(prostate, <span class="dt">package =</span> <span class="st">&quot;ElemStatLearn&quot;</span>)
?ElemStatLearn<span class="op">::</span>prostate
<span class="kw">attach</span>(prostate) </code></pre>
<p>The command <code>attach</code> allows you to access column (variables) without using <code>$</code> by adding the columns of the data frame to your work environment. <strong>Always</strong> detach the data once you are done with your analysis to avoid overriding or hidding variables.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Look at summaries of <code>lbph</code>. What likely value was imputed in places of zeros in <code>lbph</code> (before taking the logarithm)?</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">bph &lt;-<span class="st"> </span><span class="kw">exp</span>(lbph) 
<span class="kw">head</span>(bph) <span class="co">#look up first elements</span></code></pre>
<pre><code>## [1] 0.25 0.25 0.25 0.25 0.25 0.25</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">min</span>(bph) <span class="co">#return minimum</span></code></pre>
<pre><code>## [1] 0.25</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(bph, <span class="dt">main =</span> <span class="st">&quot;Histogram&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;benign prostatic hyperplasia&quot;</span>)
<span class="kw">rug</span>(bph) </code></pre>
<p><img src="LinesRModels_files/figure-html/prostate_question_b2-1.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#histogram, with lines below where the observations are</span></code></pre>
<p>It seems likely that in order to take a logarithm, zeros were changed to 0.25. As such, we have to be careful with the interpretation of this coefficient if we include <code>bph</code> in the regression.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Produce a plot of the pair of variables <code>lcavol</code> and <code>lpsa</code> on the log and on the original scale. Comment on the relationship between <code>lcavol</code> and <code>lpsa</code>.</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>)) <span class="co">#graphical parameters: two graphs per window</span>
<span class="co">#Function plot is plot(x = , y = ) or plot(y ~ x)</span>
<span class="co">#this works for vectors! (error message otherwise)</span>
<span class="kw">plot</span>(<span class="kw">exp</span>(lpsa) <span class="op">~</span><span class="st"> </span><span class="kw">exp</span>(lcavol),
<span class="dt">xlab =</span> <span class="st">&quot;Cancer volume (milliliters per cc)&quot;</span>, <span class="co">#y-axis label</span>
<span class="dt">ylab =</span> <span class="st">&quot;prostate specific antigen (ng/ml)&quot;</span>, <span class="co">#x-axis label</span>
<span class="dt">main =</span> <span class="st">&quot;Prostate cancer dataset&quot;</span>, <span class="co">#title</span>
<span class="dt">bty =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">pch =</span> <span class="dv">20</span>) <span class="co">#bty: remove box, only x-y axis</span>
<span class="co">#pch: type of plotting symbol (small filled circle)</span>
<span class="kw">plot</span>(<span class="dt">x =</span> lcavol, <span class="dt">y =</span> lpsa,
<span class="dt">xlab =</span> <span class="st">&quot;cancer volume (milliliters per cc), log scale&quot;</span>,
<span class="dt">ylab =</span> <span class="st">&quot;prostate specific antigen (ng/ml), log scale&quot;</span>, 
<span class="dt">main =</span> <span class="st">&quot;Prostate cancer dataset&quot;</span>,
<span class="dt">bty =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">pch =</span> <span class="dv">20</span>)

<span class="kw">hist</span>(<span class="kw">exp</span>(lcavol), <span class="dt">xlab =</span> <span class="st">&quot;cancer volume (milliliters per cc)&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Histogram&quot;</span>)
<span class="kw">rug</span>(<span class="kw">exp</span>(lcavol))
<span class="kw">hist</span>(<span class="kw">exp</span>(lpsa), <span class="dt">xlab =</span> <span class="st">&quot;prostate specific antigen (ng/ml)&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Histogram&quot;</span>)
<span class="kw">rug</span>(<span class="kw">exp</span>(lpsa))</code></pre>
<p>With <code>ggplot2</code>, the same graphs</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)

<span class="kw">ggplot</span>(<span class="dt">data =</span> prostate, <span class="kw">aes</span>(<span class="dt">x =</span> lcavol, <span class="dt">y =</span> lpsa)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;prostate specific antigen (ng/ml), log scale&quot;</span>,
       <span class="dt">x =</span> <span class="st">&quot;cancer volume (milliliters per cc), log scale&quot;</span>,
       <span class="dt">title =</span> <span class="st">&quot;Prostate cancer dataset&quot;</span>)</code></pre>
<p><img src="LinesRModels_files/figure-html/unnamed-chunk-11-1.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> prostate, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">exp</span>(lcavol), <span class="dt">y =</span> <span class="kw">exp</span>(lpsa))) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;prostate specific antigen (ng/ml)&quot;</span>,
       <span class="dt">x =</span> <span class="st">&quot;cancer volume (milliliters per cc)&quot;</span>,
       <span class="dt">title =</span> <span class="st">&quot;Prostate cancer dataset&quot;</span>)</code></pre>
<p><img src="LinesRModels_files/figure-html/unnamed-chunk-11-2.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> prostate, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">exp</span>(lcavol))) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">30</span>) <span class="op">+</span><span class="st"> </span><span class="kw">geom_rug</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;cancer volume (milliliters per cc)&quot;</span>,
       <span class="dt">title =</span> <span class="st">&quot;Histogram&quot;</span>)</code></pre>
<p><img src="LinesRModels_files/figure-html/unnamed-chunk-11-3.png" width="70%" style="display: block; margin: auto;" /></p>
<p>We can see that both variables are positive and positively skewed, so a log transform may lead to a more linear relationship, as indicated by the pairs plot. A multiplicative model on the original scale is thus reasonable.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Fit a linear model using the log prostate specific antigen as response variable, including a constant and the log cancer volume as covariates. Obtain numerically the OLS estimates <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> of the parameters, the fitted values <span class="math inline">\(\hat{\boldsymbol{y}}\)</span> and the residuals <span class="math inline">\(\boldsymbol{e}\)</span> using the formulae given in class.</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol, <span class="dt">data =</span> prostate)
<span class="kw">summary</span>(fit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = lpsa ~ lcavol, data = prostate)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.67624 -0.41648  0.09859  0.50709  1.89672 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.50730    0.12194   12.36   &lt;2e-16 ***
## lcavol       0.71932    0.06819   10.55   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7875 on 95 degrees of freedom
## Multiple R-squared:  0.5394, Adjusted R-squared:  0.5346 
## F-statistic: 111.3 on 1 and 95 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Create response vector and design matrix</span>
y &lt;-<span class="st"> </span>lpsa
X &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>, lcavol)
<span class="co">#Create function to compute coefs &quot;by hand&quot;</span>
coefs_vals &lt;-<span class="st"> </span><span class="cf">function</span>(x, y){
  <span class="kw">c</span>(<span class="kw">solve</span>(<span class="kw">crossprod</span>(x), <span class="kw">crossprod</span>(x, y)))
}
<span class="co"># Compute coefficients, fitted values and residuals</span>
beta_hat &lt;-<span class="st"> </span><span class="kw">coefs_vals</span>(<span class="dt">x =</span> X, <span class="dt">y =</span> lpsa)
yhat &lt;-<span class="st"> </span><span class="kw">c</span>(X <span class="op">%*%</span><span class="st"> </span>beta_hat)
e &lt;-<span class="st"> </span>y <span class="op">-</span><span class="st"> </span>yhat</code></pre>
<p>The function <code>lm</code> fits a linear model by least squares to a dataset. The function <code>summary</code> will return coefficient estimates, standard errors and various other statistics and print them in the console.</p>
<p>The formula for <code>lm</code> must be of the form <code>y ~</code>, and any combination of the variables appearing on the right hand side of the <code>~</code> will be added as new columns of the design matrix. By default, the latter includes a column of ones. To remove it, use <code>+0</code> or <code>-1</code>. If you have two covariates <code>x1</code> and <code>x2</code>, the model <code>x1+x2</code> will have for <span class="math inline">\(i\)</span>th row <span class="math inline">\((1, x_{i1}, x_{i2})\)</span>, while the model <code>x1+x2+x1:x2</code><span class="math inline">\(\equiv\)</span><code>x1*x2</code> will include an <em>interaction</em> term <code>x1:x2</code>. The latter just means product, so the <span class="math inline">\(i\)</span>th row of the design matrix would be <span class="math inline">\((1, x_{i1}, x_{i2}, x_{i1}x_{i2})\)</span>. <strong>R</strong> will drop any collinear vectors, warn you and report <code>NA</code> in the summary output.</p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Compare the quantities you obtained in the last question with the output of the function <code>lm</code>.</li>
</ol>
<pre><code>## [1] 1.5072975 0.7193204</code></pre>
<pre><code>## (Intercept)      lcavol 
##   1.5072975   0.7193204</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre><code>## [1] TRUE</code></pre>
<ol start="6" style="list-style-type: lower-alpha">
<li>Add the fitted regression line to the scatterplot of lcavol against lpsa .</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))
<span class="kw">plot</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol, <span class="dt">data =</span> prostate,
  <span class="dt">xlab =</span> <span class="st">&quot;Cancer volume (milliliters per cc), log scale&quot;</span>,
  <span class="dt">ylab =</span> <span class="st">&quot;prostate specific antigen (ng/ml), log scale&quot;</span>, 
  <span class="dt">main =</span> <span class="st">&quot;Prostate cancer dataset&quot;</span>,
  <span class="dt">bty =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">pch =</span> <span class="dv">20</span>)
<span class="kw">abline</span>(fit, <span class="dt">lwd =</span> <span class="dv">2</span>) <span class="co">#simply add regression line, lwd is line width</span></code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> prostate, <span class="kw">aes</span>(<span class="dt">x =</span> lcavol, <span class="dt">y =</span> lpsa)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;prostate specific antigen (ng/ml), log scale&quot;</span>,
       <span class="dt">x =</span> <span class="st">&quot;cancer volume (milliliters per cc), log scale&quot;</span>,
       <span class="dt">title =</span> <span class="st">&quot;Prostate cancer dataset&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</code></pre>
<p><img src="LinesRModels_files/figure-html/question_eggplot2-1.png" width="70%" style="display: block; margin: auto;" /></p>
<ol start="7" style="list-style-type: lower-alpha">
<li>Interpret the changes in prostate specific antigen (not the log prostate specific antigen), including any units in your interpretations.</li>
</ol>
<p>The interpretation is as follows. We fit
<span class="math display">\[\log(\texttt{psa}_i) = \beta_0 + \beta_1 \log(\texttt{cavol}_i) + \varepsilon_i.\]</span></p>
<p>On the original scale, this translates into the multiplicative model <span class="math inline">\(\texttt{psa}_i= \exp^{\beta_0}\texttt{cavol}_i^{\beta_1}\exp(\varepsilon_i)\)</span>.
The effect of an increase of the volume of cancer of prostate cancer by one milliliter per cubic centimeter depends on the size of the latter of <span class="math inline">\(\texttt{cavol}\)</span>, <span class="math inline">\((\texttt{cavol}_1/\texttt{cavol}_2)^{\beta_1}\)</span> for levels <span class="math inline">\(\texttt{cavol}_1\)</span> and <span class="math inline">\(\texttt{cavol}_2\)</span>.
For example, an increase of the cancer volume from 2 ml per cc to 3 ml per cc leads to an increase of the concentration of PSA of 1.34 ng/ml.</p>
<ol start="8" style="list-style-type: lower-alpha">
<li>Using the results of Exercise 4.2, obtain the orthogonal projection matrix <span class="math inline">\(\mathbf{H}_{\mathbf{X}}\)</span> and <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> using a SVD decomposition (<code>svd</code>). Check your output.</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Hat matrix</span>
Hmat &lt;-<span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span><span class="kw">solve</span>(<span class="kw">crossprod</span>(X)) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(X)
<span class="co">#SVD decomposition of X</span>
svdX &lt;-<span class="st"> </span><span class="kw">svd</span>(X)
<span class="co">#OLS coefficients</span>
beta_hat_svd &lt;-<span class="st"> </span>svdX<span class="op">$</span>v <span class="op">%*%</span><span class="st"> </span>(<span class="kw">t</span>(svdX<span class="op">$</span>u) <span class="op">%*%</span><span class="st"> </span>lpsa <span class="op">/</span><span class="st"> </span>svdX<span class="op">$</span>d)
Hmat_svd &lt;-<span class="st"> </span><span class="kw">tcrossprod</span>(svdX<span class="op">$</span>u)
<span class="co">#Check that both quantities are equal</span>
<span class="kw">all.equal</span>(Hmat, Hmat_svd, <span class="dt">check.attributes =</span> <span class="ot">FALSE</span>) </code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#use check.attributes = FALSE </span>
<span class="co">#if you want to compare only the values</span>
<span class="co">#and not e.g. the column names</span>
<span class="kw">all.equal</span>(<span class="kw">c</span>(beta_hat_svd), beta_hat)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<ol style="list-style-type: lower-roman">
<li>Compute the <span class="math inline">\(R^2_c\)</span> coefficient and compare with the one in summary output of the <code>lm</code> function. What
can you say about the explanatory power of the covariate <code>lpsa</code> ?</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">R2c &lt;-<span class="st"> </span><span class="kw">sum</span>((yhat<span class="op">-</span><span class="kw">mean</span>(y))<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="kw">sum</span>((y<span class="op">-</span><span class="kw">mean</span>(y))<span class="op">^</span><span class="dv">2</span>)
R2c_lm &lt;-<span class="st"> </span><span class="kw">summary</span>(fit)<span class="op">$</span>r.squared <span class="co">#this is centered version</span>
<span class="kw">all.equal</span>(R2c, R2c_lm)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Detach prostate from environment</span>
<span class="kw">detach</span>(prostate)</code></pre>
<p>The value of <span class="math inline">\(R^2_c\)</span> is about 0.54, so about half the variability can be explained by the model. There is reasonable explanatory power. Note that presence of cancer causes the prostate specific antigens to increase (not the other way around!). A linear model could nevertheless be sensible here if we wished to obtain a non-invasive detector for predicting presence/absence of cancer, assuming the antigen is present in blood samples, but that detection of cancer would require otherwise a biopsy.</p>
<ol start="10" style="list-style-type: lower-alpha">
<li>Perform an explanatory data analysis of the <code>prostate</code> data set. Summarize your findings.</li>
</ol>
<p>Here are some of the most important features we could detect by looking at the description, plots and summaries of the data set.</p>
<ul>
<li>Goal of the study: “PSA was proposed as a preoperative marker to predict the clinical stage of cancer”;</li>
<li>Individuals in the data set form a subset of the population of the study; the subset consists of men about to undergo radical prostatectomy. This implies they are in late stages of prostate cancer (see <code>gleason</code>);</li>
<li>No missing values, no obvious outlier;</li>
<li>Many variables are given on the log scale, potentially to remove the skewness (<code>lcavol</code>, <code>lweight</code>, <code>lcp</code>, <code>lbph</code>). This makes sense for volume (why?), less so for other variables;</li>
<li>The most relevant explanatory variables are cancer volume (<code>lcavol</code>), weight (<code>lweight</code>) and SVI (<code>svi</code>);</li>
<li>It is not clear why and how <code>pgg45</code> was constructed;</li>
<li>0.25 was added to benign prostatic hyperplasia and capsular penetration before taking the log-transform (to get <code>lbph</code> and <code>lcp</code>). It would perhaps be more adequate for interpretability to transform the capsular penetration back to the original scale;</li>
<li>The weight of the tumor (<code>lweight</code>) is correlated with benign prostatic hyperplasia (consider an interaction term);</li>
<li>Gleason is an ordered categorical, so it makes sense to cast it to a factor, with categories 6, 7 and (8,9). The seminal vesicle invasion (<code>svi</code>) is already binary;</li>
<li>Obs. 37 is the only one with a Gleason score of 8 — keeping it leads to perfect fit for this data point and will lead to problems with cross-validation if <code>gleason</code> is included as a factor in the mean model;</li>
</ul>
<p>Note that we cannot say anything about the distribution of the response <code>exp(lpsa)</code>, because the Gaussian linear model assumes the mean is <span class="math inline">\(\mathbf{X}\boldsymbol{\beta}\)</span> (so the skewness could be removed through the inclusion of covariates). Rather, one could fit both models on <code>exp(lpsa)</code> and <code>lpsa</code> scale and compare the diagnostics for the residuals.</p>

</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="summary-of-week-2.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="frischwaughlovell-theorem.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["LinesRModels.pdf", "LinesRModels.epub"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

# Analysis of variance


Consider the linear model $\boldsymbol{Y} = \mathbf{1}_n\alpha + \mathbf{Z}\boldsymbol{\beta} + \boldsymbol{\varepsilon}$
  where $\mathbf{X}=(\mathbf{1}_n^\top, \mathbf{Z}^\top)^\top$ is a full rank $n \times p$ design matrix.
  Let as usual $\mathrm{TSS} = \boldsymbol{y}^\top\mathbf{M}_{\mathbf{1}_n}\boldsymbol{y}$, the total sum of square, and $\mathrm{RSS}= \boldsymbol{y}^\top\mathbf{M}_{\mathbf{X}}\boldsymbol{y}$, the sum of squared residuals.
Under the assumptions of the Gaussian linear model (or asymptotically), the $F$-test statistic for testing the null hypothesis $\mathrm{H}_0: \boldsymbol{\beta}=\mathbf{0}_{p-1}$ against the alternative $\mathrm{H}_a: \boldsymbol{\beta} \in \mathbb{R}^{p-1}$ assuming the larger model is correctly specified is
\[F = \frac{(\mathrm{TSS}-\mathrm{RSS})/(p-1)}{\mathrm{RSS}/(n-p)}.\]
Under the null hypothesis, $F \sim \mathcal{F}(p-1, n-p)$.

An ANOVA table (`anova`) arranges the information about the sum of squares decomposition, the degree of freedom and the value of the $F$ test statistic in the following manner.

```{r, output = TRUE, echo = FALSE, results = 'markup'}
anovatab <- data.frame("Sum of squares" = c("ESS","RSS"), 
                       "degrees of freedom" = c("$p-1$","$n-p$"),
                       "scaled sum of squares" = c("$\\mathrm{ESS}/(p-1)$",
                                                   "$\\mathrm{RSS}/(n-p)$ "),
                       "Test statistic" = c("$F$",""), "$P$-value" = c("$1-\\texttt{pf}(F, p-1, n-p)$",""))
knitr::kable(anovatab, escape = FALSE, col.names = c("Sum of squares", "degrees of freedom", "scaled sum of squares", "test statistic", "$P$-value"), , booktabs = TRUE)
```


## Sum of squares decomposition

Consider the orthogonal decomposition \[\boldsymbol{y}^\top\boldsymbol{y} = \boldsymbol{y}^\top\mathbf{M}_{\mathbf{X}}\boldsymbol{y} + \boldsymbol{y}^\top\mathbf{H}_{\mathbf{X}}\boldsymbol{y},\] along with the model \[\boldsymbol{y}  = \beta_0\mathbf{1}_n + \mathbf{X}_1\boldsymbol{\beta}_1 + \mathbf{X}_2\boldsymbol{\beta}_2 + \boldsymbol{\varepsilon}.\]

We consider four concurrent models, for $\mathbf{X}_1$ an $n \times p_1$ matrix and $\mathbf{X}_2$ and $n \times p_2$ matrix and $\mathbf{X}_a = (\mathbf{1}_n^\top, \mathbf{X}_1^\top, \mathbf{X}_2^\top)^\top$ and $n \times p = n \times (1+p_1+p_2)$ full rank matrix.

(a) the full model with both predictors, $\mathrm{M}_a: \boldsymbol{y}  = \beta_0\mathbf{1}_n + \mathbf{X}_1\boldsymbol{\beta}_1 + \mathbf{X}_2\boldsymbol{\beta}_2 + \boldsymbol{\varepsilon}.$, 
(b) the restricted model with $\mathrm{M}_b: \boldsymbol{\beta}_2=0$ and only the first predictor, of the form $\boldsymbol{y}  = \beta_0\mathbf{1}_n + \mathbf{X}_1\boldsymbol{\beta}_1  + \boldsymbol{\varepsilon}.$, 
(c) the restricted model with $\mathrm{M}_c: \boldsymbol{\beta}_1=0$ and only the second predictor, of the form $\boldsymbol{y}  = \beta_0\mathbf{1}_n + \mathbf{X}_2\boldsymbol{\beta}_2 + \boldsymbol{\varepsilon}.$
(d) the intercept-only model $\mathrm{M}_d: \boldsymbol{y}  = \beta_0\mathbf{1}_n + \boldsymbol{\varepsilon}$.

Let $\mathbf{X}_a$, $\mathbf{X}_b$, $\mathbf{X}_c$, and $\mathbf{X}_d$ be the corresponding design matrices.

**R** uses an orthogonal decomposition of the projection matrix on to $\mathbf{X}_a$, $\mathbf{H}_{\mathbf{X}_a}$ into two parts: $\mathbf{H}_{\mathbf{X}_a}= \mathbf{H}_{\mathbf{X}_b} + \mathbf{H}_{\mathbf{M}_{\mathbf{X}_b}\mathbf{X}_2}.$ The last term is the contribution of $\mathbf{X}_2$ to the model fit when $\mathbf{1}_n, \mathbf{X}_1$ are already part of the model. We can form the sum of squares of the regression using this decomposition. We use the notation $\mathrm{SSR}(\mathbf{H}) = \boldsymbol{y}^\top\mathbf{H}\boldsymbol{y}$ to denote the sum of squares obtained by projecting $\boldsymbol{y}$ onto the span of $\mathbf{H}$.

We have 
\[\mathrm{SSR}(\mathbf{H}_{\mathbf{M}_{\mathbf{X}_b}\mathbf{X}_2}) = \mathrm{SSR}(\mathbf{H}_{\mathbf{X}_a}) - \mathrm{SSR}(\mathbf{H}_{\mathbf{X}_b}).\]
that is, the difference in sum of squared from the regression with model $\mathrm{M}_a$ versus that from regression $\mathrm{M}_b.$ This is the sum of squares from the regression that are due to the addition of $\mathbf{X}_2$ to a model that already contains $(\mathbf{1}_n, \mathbf{X}_1)$ as regressors.

The usual $F$-test statistic for the null hypothesis $\mathscr{H}_0: \boldsymbol{\beta}_2=0$ can be written as
\[F = \frac{\mathrm{SSR}(\mathbf{H}_{\mathbf{M}_{\mathbf{X}_b}\mathbf{X}_2})/p_2}{\mathrm{RSS}_a/(n-p)} = \frac{(\mathrm{RSS}_b-\mathrm{RSS}_a)/p_2}{\mathrm{RSS}_a/(n-p)} \sim \mathcal{F}(p_2, n-p).\]
The last equality follows by noting that  $\mathrm{SSR}(\mathbf{H}_{\mathbf{X}_b})+ \mathrm{RSS}_b=\mathrm{SSR}(\mathbf{H}_{\mathbf{X}_a})+ \mathrm{RSS}_a$.

### The decomposition of squares in **R**

Let us illustrate how to obtain the various quantities presented above using the **R** outputs.

First, we look at some data. The dataset `Chirot` from the package `carData` contains information about the 1907 Romanian peasant rebellion. We model the intensity of the rebellion as a function of commercialization of agriculture and a measure of traditionalism. We start by fitting the four models $\mathrm{M}_a, \mathrm{M}_b, \mathrm{M}_c, \mathrm{M}_d$ detailed above with the regressors $\mathbf{X}_1 \equiv$`commerce`, $\mathbf{X}_2 \equiv$`tradition` and an intercept.

```{r} 
#install.packages("carData")
data(Chirot, package = "carData")
## Fit linear model with commerce and tradition as explanatory variables
mod.a <- lm(intensity ~ commerce + tradition, data = Chirot)
mod.b <- update(mod.a, .~. - tradition)  #remove tradition
## mod.b is equivalent to 
# mod.b <- lm(intensity ~ commerce, data = Chirot)
mod.c <- update(mod.a, .~. - commerce)  #remove tradition
mod.d <- lm(intensity ~ 1, data = Chirot)
```

First, the RSS from model $\mathrm{M}_a$ can be extracted from the table returned by `summary` under the label `Residual standard error:`. This gives $\widehat{\sigma}$, and $\mathrm{RSS}_d = (n-p)\widehat{\sigma}$, where $n-p=29$ in the present setting.

```{r}
RSS.a <- crossprod(resid(mod.a))
RSS.a[1,1]
all.equal(c(RSS.a), summary(mod.a)$df[2] * summary(mod.a)$sigma^2)
```

The function `anova` outputs the following:
```{r}
anova(mod.a)
```

The function `anova` considers the *sequential* decomposition
$\mathbf{H}_{\mathbf{X}_a}=\mathbf{H}_{\mathbf{1}_n} + \mathbf{H}_{\mathbf{M}_{\mathbf{1}_n}\mathbf{X}_1} + \mathbf{H}_{\mathbf{M}_{\mathbf{X}_b}\mathbf{X}_2}$. 
The column `Sum Sq` gives 

- 1st line: the contribution for `commerce`, $\boldsymbol{y}^\top\mathbf{H}_{\mathbf{M}_{\mathbf{1}_n}\mathbf{X}_1}\boldsymbol{y}$, 
- 2nd line:  $\boldsymbol{y}^\top\mathbf{H}_{\mathbf{M}_{\mathbf{X}_b}\mathbf{X}_2}\boldsymbol{y}$ and 
- 3rd line: the residuals sum of squares $\mathrm{RSS}_a$.  

These are the conditional sum of squares from the regression for the additional variable. 
The test statistics corresponding to the $F$ and $P$-values in the table are 
\[F_1 = \frac{\mathrm{SSR}(\mathbf{H}_{\mathbf{M}_{\mathbf{1}_n}\mathbf{X}_1})/p_1}{\mathrm{RSS}/(n-p)}\]
and
\[F_2 = \frac{\mathrm{SSR}(\mathbf{H}_{\mathbf{M}_{\mathbf{X}_b}\mathbf{X}_2})/p_2}{\mathrm{RSS}/(n-p)}.\]
Note that the residual sum of squares from the denominator is that of the full model in both cases. It is orthogonal to the numerator, but not equal to the residuals from the model $\mathrm{M}_b$ for $F_1$.

Recall that the order in which the variables enter the model matters when performing model selection unless your regressors are orthogonal. We thus obtain a different output if we specify instead
```{r}
anova(lm(intensity ~ tradition + commerce, data = Chirot))
```

The `F` and `Pr(>F)` columns now correspond to
\[F_1' = \frac{\mathrm{SSR}(\mathbf{H}_{\mathbf{M}_{\mathbf{1}_n}\mathbf{X}_2})/p_2}{\mathrm{RSS}/(n-p)}\]
and
\[F_2' = \frac{\mathrm{SSR}(\mathbf{H}_{\mathbf{M}_{\mathbf{X}_c}\mathbf{X}_1})/p_1}{\mathrm{RSS}/(n-p)}.\]

### Dropping or adding variables


The function `drop1` allows you to test for model simplification, the hypothesis that either model ($b$) or model ($c$) is an adequate simplification of the full model ($a$). The output includes the RSS value in addition to the sum of squared decomposition from the previous tables. In both cases here, the null hypothesis that the simpler model with $\beta_2=0$ or $\beta_1=0$ (against the alternative that the model with $\boldsymbol{\beta} \in \mathbb{R}^2$ is correct) is rejected at significance level $\alpha = 5\%$.

```{r}
drop1(mod.a, test = 'F')
```

These $F$ values are the same as those obtained with the call on `anova` for the full model and the output is probably less confusing. 

There is a similar command to add variables, called `add1`. You can try running `add1(mod.c, scope = .~. + tradition, test = 'F')` to obtain similar output to the `anova` call.

To test for a simplified model in which many of the variables are removed, we can use the general linear hypothesis framework. The function `glht` in the package `multcomp` handles this, as does the function `linearHypothesis` in `car`.

Note that in general, multiple testing leads to inflated Type-I error for the set of tests, meaning that the probability of rejecting at least one null hypothesis for $m$ tests provided that they are all true is greater than the significance level $\alpha$ of the individual tests. A Bonferroni correction (take $\alpha/m$ as level if you perform $m$ tests) could be made to alleviate this, but the power to detect will be lower.

```{r}
#install packages `multcomp` and `car` if necessary
#Test both hypothesis separately with Bonferroni correction
jt_test <- multcomp::glht(mod.a, linfct = rbind(c(0, 1, 0), c(0, 0, 1)), 
                          test = adjusted("bonf"))
summary(jt_test)
summary(jt_test, multcomp::Ftest())
#Test hypothesis jointly using GLHT
car::linearHypothesis(mod.a, hypothesis.matrix = rbind(c(0, 1, 0), c(0, 0, 1)), test = "F")
```

You can also use the function ANOVA to test with nested model. The syntax is slightly different, but the output is exactly the same. 

```{r}
#Simpler to more complex nested models
anova(mod.d, mod.a)
```

At this point, it is important to note that we will get different test statistics (due to different denominator) if we consider the residuals sum of squares (RSS) from the full model or the simplified model in the $F$-test. The test is sensitive to model misspecification and we must make sure the residual sum of squares in the denominator is at least consistent.

### Biased estimators of the residual sum of square {#biased-rss}

There are two possible scenarios:

1. Underfitting: you omit a variable that should be present in the model (misspecified model).

Omitting relevant variables undully inflates the residual sum of squares. Indeed, if the true model is $\mathrm{M}_a$ with $\beta_2 \neq 0$, but that we fit model $\mathrm{M}_b$ of the form $\boldsymbol{y}  = \beta_0\mathbf{1}_n + \mathbf{X}_1\boldsymbol{\beta}_1  + \boldsymbol{\varepsilon}$, then the residuals sum of squares we obtain will be $\mathrm{RSS}_{a} + \mathrm{SSR}( \mathbf{H}_{\mathbf{M}_{\mathbf{X}_b}\mathbf{X}_2})$. This reduces the statistical significance of the other variables in turn because the $F$-statistic is pulled toward zero. Since our null hypothesis is that the simpler model is adequate, our power to reject the null is smaller and we will go for much simpler models than should be used.

2. Overfitting: suppose on the contrary that we use a bigger model $\mathrm{M}_a$ with spurious variables (overfit) and that the true model is $\mathrm{M}_b$. The parameter estimate $\hat{\beta}_2$ should have expectation zero and, as a result, the additional decrease in the sum of squared residuals should be also zero for the redundant variable conditional on the rest. The estimator is still unbiased; the only difference is that we use up additional degrees of freedom in the test.


This is best illustrated using a little simulation:

```{r}
set.seed(1234) #RNG sequence - makes output reproducible
x1 <- rnorm(100)
x2 <- rexp(100)
x3 <- rbinom(n = 100, size = 100, p = 0.2)
x4 <- runif(100)
y <- x1 + x2 + x3 + rnorm(100, sd = 4)
#RSS/(n-p)
a_u <- anova(lm(y ~ x1 + x2)) #underfit
a_c  <- anova(lm(y ~ x1 + x2 + x3)) #correct
a_o <- anova(lm(y ~ x1 + x2 + x3 + x4 )) #overfit

print(c("Underfit" = a_u['Residuals','Mean Sq'], 
         "Correct" = a_c['Residuals','Mean Sq'], 
        "Overfit" = a_o['Residuals','Mean Sq']
))
#What is Underfit sum of square?
(a_c['Residuals','Sum Sq'] + a_c['x3','Sum Sq'])/(a_c['Residuals','Df'] + 1)
```


If there are no interactions and you wish to compare main effects conditional on all the others main effects present in the model for each of the explanatory variables, you can use the function `Anova` from the package `car`. This is the so-called Type II Anova decomposition. You could retrieve the output directly from repeated calls to `anova`. 
<!--
See this [post](http://goanna.cs.rmit.edu.au/~fscholer/anova.php) for more details. 
-->

## One-way ANOVA

A one-way ANOVA is a test for equality of means in different subpopulations. Under the assumption that the observations have a common variance and that they are normally distributed, this corresponds to a Gaussian linear model with binary indicators (factors) as explanatories.
Suppose there are $L$ possible levels and $n_j$ is the number of observations for group $j=1,\ldots, L$. 

The one-way ANOVA model can be written as
\[y_{i_j,j} = \alpha_j + \varepsilon_{i_j,j}, \quad  \varepsilon_{i_j,j} \stackrel{\mathrm{iid}}{\sim} \mathcal{N}(0, \sigma^2)\qquad (j = 1, \ldots, L, i_j= 1, \ldots, n_j). \]
Let $\boldsymbol{y}_j = (y_{1,j}, \ldots, y_{n_j, j})^\top$ denote the vector of observations for the first group and similarly for $\boldsymbol{\varepsilon_j}$; we can stack observations into a single regression with a matrix $\mathbf{X}$ of indicators variables, viz.
\[\begin{pmatrix}\boldsymbol{y}_1 \\\boldsymbol{y}_2 \\ \vdots \\ \boldsymbol{y}_L\end{pmatrix} = \begin{pmatrix} \mathbf{1}_{n_1} & \mathbf{0}_{n_1}&\cdots & \mathbf{0}_{n_1} \\
\mathbf{0}_{n_2} & \mathbf{1}_{n_2}&\ddots & \mathbf{0}_{n_2} \\
\vdots & \ddots & \ddots & \vdots\\
\mathbf{0}_{n_L} & \mathbf{0}_{n_L}&\cdots & \mathbf{1}_{n_L} 
\end{pmatrix}\begin{pmatrix} \alpha_1 \\ \alpha_2 \\\vdots \\ \alpha_L\end{pmatrix} + \begin{pmatrix}\boldsymbol{\varepsilon}_1 \\\boldsymbol{\varepsilon}_2 \\ \vdots \\ \boldsymbol{\varepsilon}_L\end{pmatrix}. \]

In a **balanced design**, the number of observations $m$ is the same for each of the $L$ levels of the factor. We can then write $\mX^\top\mX = m\mathbf{I}_L$ and the standard errors are the same.

To test $\mathrm{H}_0: \alpha_1 = \cdots = \alpha_L$, we can use the usual sum of squares decomposition. 
The $F$-statistic for this test is 
\[F = \frac{(\boldsymbol{y}^\top\mathbf{M}_{\mathbf{1}_n}\boldsymbol{y} - \boldsymbol{y}^\top\mathbf{M}_{\mathbf{X}}\boldsymbol{y})/(L-1)}{
\boldsymbol{y}^\top\mathbf{M}_{\mathbf{X}}\boldsymbol{y}/(n-L)} \sim \mathcal{F}(L-1, n-L).\]
and we reject the null hypothesis $\mu_1 = \cdots = \mu_L$ against the alternative that at least one group mean is different. One crucial assumption is that all groups have the same variance.

## Two-way ANOVA and irrelevant hypotheses

 A two-way analysis extends the one-way ANOVA by considering two factors $\mathbf{D}_1$ and $\mathbf{D}_2$ respectively taking $L_1$ and $L_2$ levels.
The full model with interactions is usually specified using the design matrix 
$\mathbf{X} = [\mathbf{1}_n, \mathbf{D}_{1}, \mathbf{D}_2, (\mathbf{D}_1\circ \mathbf{D}_2) ]$, so the mean model is
 \begin{align*}
  \mathrm{E}(Y_{i})= \omega + \sum_{j=1}^{L_1-1} \beta_j\I{D_{i1}=j+1} + \sum_{k=1}^{L_2-1}
  \gamma_k\I{D_{i2}=k+1} + \sum_{j=1}^{L_1-1}\sum_{k=1}^{L_2-1} \nu_{jk}\I{D_{i1}=j+1}\I{D_{i2}=k+1}.
 \end{align*}
Different submodels can be specified:

i. the intercept-only model, $M_1$, has 1 parameter ($\nu_{jk}=\beta_j=\gamma_k=0, j=1, \ldots, L_1-1, k = 1, \ldots, L_2-1$)
ii. the model $M_2$ with only the second factor ($\nu_{jk}=\beta_j=0, j=1, \ldots, L_1-1, k = 1, \ldots, L_2-1$) has $L_2$ parameters
iii. the model $M_3$ with only the first factor ($\nu_{jk}=\gamma_k=0, j=1, \ldots, L_1-1, k = 1, \ldots, L_2-1$) has $L_1$ parameters
iv. the additive model $M_4$ ($\nu_{jk}=0, j=1, \ldots, L_1-1, k = 1, \ldots, L_2-1$), has $L_1+L_2-1$ parameters;
v. the additive model $M_5$ with the interaction term  has $L_1L_2$ parameters;


Note that we consider interaction terms only if the corresponding main effects are included. Removing main effects or lower-order
interactions while keeping higher order terms implies that the levels of the factor are not arbitrarily labelled and
rearrangement of the factors (changing the baseline) leads to potentially different conclusion.

To see this, consider the model with design matrix 
$[\mathbf{1}_n, \mathbf{D}_{1}, (\mathbf{D}_1\circ \mathbf{D}_2)]$, so 
$\gamma_k=0$  $(k = 1, \ldots, L_2-1)$.

The mean level for observations in the different groups are
\begin{align*}
\mathrm{E}(Y_i \mid D_{i1}=1, D_{i2}=k) &= \omega \\
\mathrm{E}(Y_i \mid D_{i1}=j, D_{i2}=1; j > 1) &= \omega + \beta_j \\
\mathrm{E}(Y_i \mid D_{i1}=j, D_{i2}=k; j, k > 1) &= \omega + \beta_j + \nu_{jk} \\
\end{align*}
The effect of moving from level $D_{2}=1$ to $D_{2}=k>1$ is zero if $D_{1}=1$, whereas it is $\nu_{jk}$ if $D_{1}>1$. We therefore are treating the levels as being different and the models fitted (and the inference) will differ if we change the baseline category for the factors. This means that the latter is no longer arbitrary! 
In **R** this baseline is the first factor in alphabetical order, so is essentially arbitrary. In the same way we will not consider interactions without main effects, one would not consider polynomials of degree $k$ without including the coefficients of the lower order. For a degree two polynomial of the form $\sum_{i=0}^k \beta_ix^i$, testing the hypothesis $\beta_i=0$ for $i < k$ means restricting attention to polynomials whose $k$th order term is zero, which is usually nonsensical. Thus, any Wald test (the $t$ values output by `summary`) corresponding to such an hypothesis should be disregarded.


## Solutions

### Exercise 9.3 - One-way analysis of variance

In this example, the three groups have very different variances! We carry out the testing procedure simply to show you how it is done (this does not imply we should use it in practice).

```{r}
options(show.signif.stars = FALSE)
#http://www.stat.ufl.edu/~winner/data/meniscus.txt
meniscus <- read.table("https://lbelzile.bitbucket.io/math341/meniscus.dat", header = TRUE)
boxplot(displacement ~ method, data = meniscus, ylab = "Displacement (in mm)")
lmod_men <- lm(displacement ~ method, data = meniscus)
summ_men <- summary(lmod_men)
#ANOVA table
anov_men <- anova(lmod_men)
#F statistic with dof
summ_men$fstatistic

#P-value
anov_men[1,"Pr(>F)"]
```

The $F$ statistic for the null hypothesis $\mu_1=\mu_2=\mu_3$ is `r round(as.vector(summ_men$fstatistic[1]), 2)` against the alternative that at least one group mean differ. Under the assumption of the Gaussian linear model, $F$ follows a Fisher distribution with `r as.integer(summ_men$fstatistic[2])` and `r as.integer(summ_men$fstatistic[3])` degrees of freedom. The $P$-value is thus `r round(anov_men[1,"Pr(>F)"], 2)` and we therefore reject the null hypothesis that the treatment is equal at level $\alpha = 0.05$.

The `meniscus` dat set is a balanced design, which implies that the number of observations is the same for each level of the factor. Since the entries of $\mathbf{X}^\top\mathbf{X}$ depend on the counts for each level, they will be the same here. This implies that the standard errors are also identical for each level (except for the baseline, symbolized by the intercept). Removing the latter changes the parametrization from baseline and constrast to individual group mean.


```{r}
summary(lmod_men2 <- lm(displacement ~ 0 + method, data = meniscus))
crossprod(model.matrix(lmod_men2))
```


Note that the value of the multiple R-squared value is not the same, nor is the $F$-statistic. The residuals sum of square does not change because the adjustment is the same. However, without an intercept, **R** computes the decomposition 
$\boldsymbol{y}^\top\boldsymbol{y} = \mathrm{RSS} + \boldsymbol{y}^\top\mathbf{H}_{\mathbf{X}}\boldsymbol{y}$ rather than $\mathrm{TSS} = \boldsymbol{y}^\top\mathbf{M}_{\mathbf{1}_n}\boldsymbol{y}= \mathrm{ESS}+\mathrm{RSS}$.
We have $\mathrm{TSS} = \bs{y}^\top\bs{y}-n\bar{y}^2$.

We can compute the mean using the information on the total number of cases, since $\bar{y} = (\hat{\mu}_1+\hat{\mu}_2 + \hat{\mu}_3)/3$.


### Exercise 9.4 - Two-way analysis of variance

```{r}
diet <- read.table("https://lbelzile.bitbucket.io/math341/diet.dat", header = TRUE)
#Cast strings to factors
diet$diet.type <- as.factor(diet$diet.type)
diet$gender <- as.factor(diet$gender)

#Check mean and variance by combination of factor
#Warning: small sample sizes
facs <- list(diet$diet.type, diet$gender)
tapply(diet$weight.loss, facs, mean)
tapply(diet$weight.loss, facs, var)
#Variance may not be homogeneous for men/women 
#Fit model with interaction
M5 <- lm(weight.loss ~ gender * diet.type, data = diet)
M4 <- lm(weight.loss ~ gender + diet.type, data = diet)
M3 <- lm(weight.loss ~ diet.type, data = diet)
M2 <- lm(weight.loss ~ gender, data = diet)
M1 <- lm(weight.loss ~ 1, data = diet)
#ANOVA Tables (recall sequential decomposition) - prefered option
anova(M5)
#anova(M5) uses RSS from M5 in denominator, read table from bottom to top
#RSS values
RSS <- anova(M1, M2, M3, M4, M5)[,"RSS"]
#Backward model selection (more complex to simpler)
drop1(M5, test = "F")
#Manual calculation
F45 <- ((RSS[4]-RSS[5])/2)/(RSS[5]/M5$df.residual)
```

For forward model selection, we select the covariate that is the most correlated with the response first. The residual sum of square of the denominator must be correct, so we could use that of the most complex model here.

```{r forward_diet}
anova(lm(weight.loss ~ gender * diet.type, data = diet))["gender", c("F value","Pr(>F)")] 
#gender is not significant
anova(lm(weight.loss ~ diet.type * gender, data = diet))["diet.type", c("F value","Pr(>F)")] 
#diet type is significant

#Alternatively - assume that the model is CORRECT
## Clearly not the case
add1(M1, scope = c("diet.type","gender"), test = "F")
#manually computing F-test between diet.type + intercept and intercept only
isTRUE(all.equal( 
  ((RSS[1]-RSS[3])/2)/(RSS[3]/(73)), 
  add1(M1, scope = c("diet.type","gender"), test = "F")["diet.type", "F value"]))
                 
#Note that in the above, the RSS is that of the more complex model, but not the full model
add1(M3, scope = "gender", test = "F")
#No evidence against the simpler null model with only diet
#We do not test for the interaction model without main effects included!
```

We can use information criterion to estimate the goodness-of-fit of the model.
The Akaike's information criterion (AIC) and Schwartz' information criterion (BIC) can be obtained by use of the functions `AIC` and `BIC`, respectively.

An alternative is Mallow's $C_p$, which requires an estimate of $s^2$. It is customary to select $s^2$ as the mean residual sum of squares from the most complex model, to make the comparisons fair avoid bias to due model misspecification.
The most complex model will by construction give $C_p=p$ (so we cannot assess the goodness-of-fit of this model using this technique). Good models are those for which the value of $C_p$ is close to $p$.

```{r}
p <- unlist(lapply(list(M1, M2, M3, M4, M5), 
                   FUN = function(mod){length(coef(mod))}))
Mallow_Cp <- RSS/RSS[5]*(nrow(diet)-p[5]) - nrow(diet) + 2 * p
Mallow_Cp

#Step function for model selection using AIC/BIC
#step(M5, direction = 'backward',trace = FALSE, k = log(76))

#Alternatively, compute each AIC/BIC value
aic_val <- AIC(M1, M2, M3, M4, M5)
bic_val <- BIC(M1, M2, M3, M4, M5)
which.min(aic_val$AIC)
which.min(bic_val$BIC)

#Store values in table
ICvals <- rbind(aic_val$AIC, bic_val$BIC)
colnames(ICvals) <- paste0("M", seq(1:5))
rownames(ICvals) <- c("AIC", "BIC")
#Create table for Markdown
knitr::kable(round(ICvals,2))
#Create table to export in LaTeX
tab <- xtable::xtable(round(ICvals,1), caption = "Two-way ANOVA, diet data")
#print(tab, booktabs = TRUE)
```

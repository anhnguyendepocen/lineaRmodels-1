# Generalized linear models

In class, we have covered basic of generalized linear models (GLM), including binary and binomial models with logistic link function and the Poisson regression model with log link. The unifying theory behind GLM will be covered in MATH 408. The goal of this tutorial is to give you additional examples on how to fit these models. 

Outside of parameter estimation (which proceeds through Fisher scoring in R), we will look at analysis of deviance (a likelihood ratio test for testing whether coefficients are zero, resulting in a comparison between two nested models). We proceed with the latter in exactly the same way as for analysis of variance, modulo the fact that we use the $\chi^2$ asymptotic distribution in place of the Fisher $F$ distribution. Similarly, the $P$-values for the Wald tests are based on the asymptotic distribution of the test, which is Gaussian.


The specification of the GLM object in **R** is analogous to the one for an `lm` object. 
We use `y ~ x` formula syntax to specify the mean relationship. If you have a binomial data, the response should be a two column matrix with integer elements $(k_i, n_i-k_i)$ specifying the number of successes and failures, respectively, for each case or cell. 

The second difference between `lm` and `glm` is the presence of the argument `family` that allow you to specify the likelihood

- `family = gaussian()` gives back a linear model;
- `family = binomial("logit")` gives you a binary or binomial regression with logistic link function; 
- `family = poisson()` gives you Poisson regression.

By default, empty parenthesis give the so-called canonical link function (identity for normal, logit for binomial and log for Poisson).

Let $\ell$ denote the log-likelihood function for an $n$ sample. The function `glm` uses Fisher scoring to obtain the maximum likelihood estimates, based on the recursion
\[ \boldsymbol{\beta}^{(t+1)} = \boldsymbol{\beta}^{(t)} + \mathcal{I}^{-1}_n(\boldsymbol{\beta}^{(t)}) \left. \frac{\partial \ell}{\partial \boldsymbol{\beta}} \right|_{\boldsymbol{\beta}=\boldsymbol{\beta}^{(t)} },\]
where the Fisher information
\[\mathcal{I}_n =\mathrm{E}\left(  \frac{\partial \ell}{\partial \boldsymbol{\beta}}\frac{\partial \ell}{\partial \boldsymbol{\beta}^\top}\right)\]
is estimated at the current value of $\boldsymbol{\beta}^{(t)}$. The IRLS algorithm uses the observed information.

## Diagnostics for Bernoulli data

This is the example presented in class. The response variable is a binary indicator of low birthweight.


```{r binaryglmexample}
data(birthwt, package = "MASS")
# Preprocessing from MASS - give meaningful labels for factors
# See help for description of the data set
# Rewrite a new data frame with those variables
bwt <- with(birthwt, {
  race <- factor(race, labels = c("white", "black", "other"))
  ptd <- factor(ptl > 0)
  ftv <- factor(ftv) 
  # Group number of visits to avoid categories with small counts
  levels(ftv)[-(1:2)] <- "2+"
  data.frame(low = factor(low), age, lwt, race, smoke = (smoke > 0),
             ptd, ht = (ht > 0), ui = (ui > 0), ftv)
  })

lbw <- glm(low ~ ., family = binomial, data = bwt)
# Can use summary just like for lm
summary(lbw)
```

The `summary` object returns the coefficients, standard errors and results for the Wald test that $\beta_i=0$. Note that these will generally differ from the likelihood ratio test. 
The code above illustrates how to fit the Bernoulli model. Since the data are binary, there is no need to give two columns as response. The following code produces diagnostics for the model as shown in class:

```{r glmdiag}
binmod <- glm(formula = low ~ lwt + race + smoke + ptd + ht + ui, 
           family = binomial(link = "logit"), data = bwt)
#Logit link function
logit <- function(x){log(x)-log(1-x)}
n <- length(fitted(binmod))
U1 <- runif(n, min = 0, max = fitted(binmod))
U2 <- runif(n, min = fitted(binmod), max = 1)
unires <- binmod$y*U1 + U2*(1-binmod$y)
par(pty = "s", mfrow = c(2, 2), bty = "l", pch = 20)
plot(bwt$lwt, unires, ylab = "uniform residuals",
     xlab = "mother's weight (in pounds)")
plot(logit(fitted(binmod)), unires, ylab = "uniform residuals",
     xlab = "logit(p)")
hist(unires, probability = TRUE, main = "", xlab = "uniform residuals")

# Quantile - quantile plot
plot(x = rank(unires)/(n + 1), y = unires, 
     xlab = "Theoretical quantiles", ylab = "Observed quantiles", 
     xlim = c(0, 1), ylim = c(0, 1), cex = 0.5)
abline(a = 0, b = 1)
# Simulated confidence bands, based on quantiles of the uniform distribution
pconfint <- apply(apply(matrix(runif(10000 * n), nrow = n), 2, sort), 1, quantile, probs = c(0.025, 0.975))
lines((1:n)/(n+1), pconfint[1,], lty = 2, col = 2)
lines((1:n)/(n+1), pconfint[2,], lty = 2, col = 2)

```


## Poisson model for contingency table

We analyze a $4 \times 3$ contingency table containing information about tumour type.
The first factor is cancer `type`, with levels

1. Hutchinson's melanotic freckle, 
2. Superficial spreading melanoma, 
3. Nodular
4. for Indeterminate type

The second variable, `site`, is one of 
1. Head and Neck, 
2. Trunk,
3. Extremities

The data are count, hence we proceed with the analysis using a Poisson likelihood. This ressembles ANOVA models with factors.

```{r poissonexample }
# Create dataset
site <- gl(n = 3, k = 1, length = 12) 
# gl generates levels of a factor
tumor <- gl(n = 4, k = 3) #each 3
cases <- c(22, 2, 10, 16, 54, 115, 19, 33, 73, 11, 17, 28)
cancer <- data.frame(tumor, site, cases)
# Four cases - no effect, main interaction only, additive
cancer.m0 <- glm(cases ~ 1, family = poisson, data = cancer)
cancer.m1 <- glm(cases ~ tumor, family = poisson, data = cancer)
cancer.m2 <- glm(cases ~ site, family = poisson, data = cancer)
cancer.m3 <- glm(cases ~ tumor + site, family = poisson, data = cancer)
# Saturated model
cancer.m4 <- glm(cases ~ tumor * site, family = poisson, data = cancer)
# Analysis of deviance
# Same syntax as for GLM
drop1(cancer.m4)
anova(cancer.m3, cancer.m4, test = "Chisq")
# anova(cancer.m4) returns three tests, 
# but only the comparison with additive model is justified
summary(cancer.m4)
# Alternatively, compute manually
1 - pchisq(deviance(cancer.m3), df = cancer.m3$df.residual)
```

The likelihood ratio test to check whether the interaction is significative is soundly rejected, hence we would keep the saturated model. For such a model, the fitted values correspond to the observed counts. 

This is an example where the hypothesis of equal mean and variance does not seem to hold. Handling the overdispersion is beyond the scope of this course.

## Solutions

### Exercise 13.3 - Two-way contingency tables

```{r cancer_glm}
cancer <- read.table("https://lbelzile.bitbucket.io/math341/cancer.dat", header = TRUE)
print(cancer)
# Some categories have small counts, so asymptotic result may be a bit off

cancer.m0 <- glm(cbind(yes, no) ~ 1, family = "binomial", data = cancer)
cancer.m1 <- glm(cbind(yes, no) ~ age, family = "binomial", data = cancer)
cancer.m2 <- glm(cbind(yes, no) ~ malignant, family = "binomial", data = cancer)
cancer.m3 <- glm(cbind(yes, no) ~ age + malignant, family = "binomial", data = cancer)
cancer.m4 <- glm(cbind(yes, no) ~ age * malignant, family = "binomial", data = cancer)
library(xtable)
devtab <- data.frame("model" = c("M0","M1","M2","M3"), 
                     "deviance" = round(c(deviance(cancer.m0), deviance(cancer.m1), 
                                          deviance(cancer.m2), deviance(cancer.m3)), 2),
      "p" = c(length(coef(cancer.m0)),length(coef(cancer.m1)),
              length(coef(cancer.m2)),length(coef(cancer.m3))))

devtab
```

Now that we have calculated the deviance of every model, we can perform an analysis of deviance and check 
whether the final model obtained by backward elimination is adequate by comparing its $P$-value under the null.
Some counts in the age category `70+` are very low, hence the asymptotic result can be a bit off. We assess this through a small simulation study in which we resample observations from the fitted model.


```{r glmcancer2, cache = TRUE}
# Saturated model vs additive model
 1- pchisq(deviance(cancer.m3), df = nrow(cancer) - length(cancer.m3$coef))
# p-value of 0.78, fail to reject null that additive model is adequate
# Try further simplification
drop1(cancer.m3, test = "Chisq")
# Fail to reject null that model with only "malignant" is adequate simplification
 1- pchisq(2*(c(logLik(cancer.m3) - logLik(cancer.m2))), df = (length(cancer.m3$coef) - length(cancer.m2$coef)))
 1- pchisq(2*(c(logLik(cancer.m3) - logLik(cancer.m1))), df = (length(cancer.m3$coef) - length(cancer.m1$coef)))
drop1(cancer.m2, test = "Chisq")
# Reject null that model with only intercept is adequate

# If Model is adequate, Deviance approx JK-p 
deviance(cancer.m2)
# Is this result vary large? Investigate via simulation study
# Canonical link functions for binomial
logit <- function(x){log(x) - log(1-x)}
# Inverse link function (logistic in course notes)
expit <- function(x){ 1/(1+ exp(-x))}
# Get predicted probability
probc <- expit(predict(cancer.m2))
# Need to condition on total count - fixed for binomial model
nr <- rowSums(cancer[,c("yes","no")])
# Simulate new datasets from the model, compute their deviance
simudev <- rep(0, 1e3L)
for(i in 1:length(simudev)){
  newyes <- sapply(1:length(nr), function(j){rbinom(n = 1, size = nr[j], prob = probc[j])})
  newcancer <- data.frame(malignant = cancer$malignant, yes = newyes, no = nr - newyes)
  simudev[i] <- deviance(glm( cbind(yes, no) ~ malignant, family = "binomial", data = newcancer))
}
# Distribution of deviance from simulated model, conditional on row total
hist(simudev, main = "Deviance of simulated models", xlab = "Deviance", probability = TRUE, ylim = c(0, 0.2), breaks = 20)
# Line corresponding to deviance of 
abline(v = deviance(cancer.m2), lty = 2)
# Null distribution
curve(dchisq(x, df = cancer.m2$df.residual), col = 2, add = TRUE)
# P-value from simulation
sum(I(deviance(cancer.m2) < simudev)) / length(simudev)
# P-value with asymptotic distribution
1-pchisq(deviance(cancer.m2), df = (nrow(cancer) - length(coef(cancer.m2))))
# About 4% difference between the two
```


### Exercise 13.5 - Equivalence of binomial and Poisson models

We can fit the model using the Poisson generalized linear model with an offset term for `log(pop)`, since the latter is fixed. We cannot make direct comparisons because the population size in each category are different. If $X \sim \mathcal{B}(m_i, \pi_i)$, the Poisson approximation is $X \sim \mathcal{P}(\lambda_i)$ with $\lambda_i \approx m_i\pi_i$. Taking logarithms, we get $\log(\lambda_i) = \log(m_i) + \log(\pi_i)$. The term $\log(m_i)$ is an offset with known coefficient of 1.

```{r smokingglm}
smoking <- read.table("https://lbelzile.bitbucket.io/math341/smoking.dat", header = TRUE)
smoking.p.m0 <- glm(dead ~ offset(log(pop)), family = poisson, data = smoking)
smoking.p.m1 <- glm(dead ~ offset(log(pop)) + smoke, family = poisson, data = smoking)
smoking.p.m2 <- glm(dead ~ offset(log(pop)) + age, family = poisson, data = smoking)
smoking.p.m3 <- glm(dead ~ offset(log(pop)) + smoke + age, family = poisson, data = smoking)
#Define quantities
n <- nrow(smoking)
p0 <- length(coef(smoking.p.m0)); D0p <- deviance(smoking.p.m0)
p1 <- length(coef(smoking.p.m1)); D1p <- deviance(smoking.p.m1)
p2 <- length(coef(smoking.p.m2)); D2p <- deviance(smoking.p.m2)
p3 <- length(coef(smoking.p.m3)); D3p <- deviance(smoking.p.m3)

#Analysis of deviance
1 - pchisq(D3p, df = n - p3) # Interaction not stat. significative
1 - pchisq(D2p - D3p, df = p3 - p2) # smoke significative
1 - pchisq(D1p - D3p, df = p3 - p1) # age significative
#If Model is correct, D3 approx chisq(n - p3)
summary(smoking.p.m3)

#Same with binomial model
smoking.b.m0 <- glm(cbind(dead, pop - dead) ~ 1, family = binomial, data = smoking)
smoking.b.m1 <- glm(cbind(dead, pop - dead) ~ smoke, family = binomial, data = smoking)
smoking.b.m2 <- glm(cbind(dead, pop - dead) ~ age, family = binomial, data = smoking)
smoking.b.m3 <- glm(cbind(dead, pop - dead) ~ smoke + age, family = binomial, data = smoking)
#Define quantities
n <- nrow(smoking)
D0b <- deviance(smoking.b.m0)
D1b <- deviance(smoking.b.m1)
D2b <- deviance(smoking.b.m2)
D3b <- deviance(smoking.b.m3)

1 - pchisq(D3b, df = n - p3) # Interaction not stat. significative
1 - pchisq(D2b - D3b, df = p3 - p2) # smoking group significative
1 - pchisq(D1b - D3b, df = p3 - p1) # age group significative
#If Model is correct, D3 approx n - p3
summary(smoking.b.m3)
# Output deviance table
devtab <- data.frame("model" = c("M0","M1","M2","M3"), 
                     "deviance binom." = round(c(D0p, D1p, D2p, D3p), 2),
                     "deviance Poisson" = round(c(D0b, D1b, D2b, D3b), 2),
                     "p" = c(p0, p1, p2, p3))
print(devtab)
#To export to LaTeX
#xtab <- xtable(devtab, caption = "Analysis of deviance for the \\texttt{smoking} data set")
#print(xtab, booktabs = TRUE, sanitize.text.function = identity, include.rownames = FALSE, )

# Compare fitted probabilities
par(mar = c(6,6,3,3))
plot(fitted(smoking.b.m3), fitted(smoking.b.m3) - fitted(smoking.p.m3)/smoking$pop,
     xlab = "Fitted probability of death\n from logistic model",
     ylab = "Difference in fitted probability of death \nbetween Poisson and logistic models",
     main = "Smoking cancer dataset", bty = "l")
#Differ most for last categories in which the Poisson approximation is dubious
```
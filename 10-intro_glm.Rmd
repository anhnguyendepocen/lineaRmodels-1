# Generalized linear models

In class, we have covered basic of generalized linear models (GLM), including binary and binomial models with logistic link function and the Poisson regression model with log link. The unifying theory behind GLM will be covered in MATH 408. The goal of this tutorial is to give you additional examples on how to fit these models. 

Outside of parameter estimation (which proceeds through Fisher scoring in R), we will look at analysis of deviance (a likelihood ratio test for testing whether coefficients are zero, resulting in a comparison between two nested models). We proceed with the latter in exactly the same way as for analysis of variance, modulo the fact that we use the $\chi^2$ asymptotic distribution in place of the Fisher $F$ distribution. Similarly, the $P$-values for the Wald tests are based on the asymptotic distribution of the test, which is Gaussian.


The specification of the GLM object in **R** is analogous to the one for an `lm` object. 
We use `y ~ x` formula syntax to specify the mean relationship. If you have a binomial data, the response should be a two column matrix with integer elements $(k_i, n_i-k_i)$ specifying the number of successes and failures, respectively, for each case or cell. 

The second difference between `lm` and `glm` is the presence of the argument `family` that allow you to specify the likelihood

- `family = gaussian()` gives back a linear model;
- `family = binomial("logit")` gives you a binary or binomial regression with logistic link function; 
- `family = poisson()` gives you Poisson regression.

By default, empty parenthesis give the so-called canonical link function (identity for normal, logit for binomial and log for Poisson).

Let $\ell$ denote the log-likelihood function for an $n$ sample. The function `glm` uses Fisher scoring to obtain the maximum likelihood estimates, based on the recursion
\[ \boldsymbol{\beta}^{(t+1)} = \boldsymbol{\beta}^{(t)} + \mathcal{I}^{-1}_n(\boldsymbol{\beta}^{(t)}) \left. \frac{\partial \ell}{\partial \boldsymbol{\beta}} \right|_{\boldsymbol{\beta}=\boldsymbol{\beta}^{(t)} },\]
where the Fisher information
\[\mathcal{I}_n =\mathrm{E}\left(  \frac{\partial \ell}{\partial \boldsymbol{\beta}}\frac{\partial \ell}{\partial \boldsymbol{\beta}^\top}\right)\]
is estimated at the current value of $\boldsymbol{\beta}^{(t)}$. The IRLS algorithm uses the observed information.

## Diagnostics for Bernoulli data

This is the example presented in class. The response variable is a binary indicator of low birthweight.


```{r binaryglmexample}
data(birthwt, package = "MASS")
# Preprocessing from MASS - give meaningful labels for factors
# See help for description of the data set
# Rewrite a new data frame with those variables
bwt <- with(birthwt, {
  race <- factor(race, labels = c("white", "black", "other"))
  ptd <- factor(ptl > 0)
  ftv <- factor(ftv) 
  # Group number of visits to avoid categories with small counts
  levels(ftv)[-(1:2)] <- "2+"
  data.frame(low = factor(low), age, lwt, race, smoke = (smoke > 0),
             ptd, ht = (ht > 0), ui = (ui > 0), ftv)
  })

lbw <- glm(low ~ ., family = binomial, data = bwt)
# Can use summary just like for lm
summary(lbw)
```

The `summary` object returns the coefficients, standard errors and results for the Wald test that $\beta_i=0$. Note that these will generally differ from the likelihood ratio test. 
The code above illustrates how to fit the Bernoulli model. Since the data are binary, there is no need to give two columns as response. The following code produces diagnostics for the model as shown in class:

```{r glmdiag}
binmod <- glm(formula = low ~ lwt + race + smoke + ptd + ht + ui, 
           family = binomial(link = "logit"), data = bwt)
#Logit link function
logit <- function(x){log(x)-log(1-x)}
n <- length(fitted(binmod))
U1 <- runif(n, min = 0, max = fitted(binmod))
U2 <- runif(n, min = fitted(binmod), max = 1)
unires <- binmod$y*U1 + U2*(1-binmod$y)
par(pty = "s", mfrow = c(2, 2), bty = "l", pch = 20)
plot(bwt$lwt, unires, ylab = "uniform residuals",
     xlab = "mother's weight (in pounds)")
plot(logit(fitted(binmod)), unires, ylab = "uniform residuals",
     xlab = "logit(p)")
hist(unires, probability = TRUE, main = "", xlab = "uniform residuals")

# Quantile - quantile plot
plot(x = rank(unires)/(n + 1), y = unires, 
     xlab = "Theoretical quantiles", ylab = "Observed quantiles", 
     xlim = c(0, 1), ylim = c(0, 1), cex = 0.5)
abline(a = 0, b = 1)
# Simulated confidence bands, based on quantiles of the uniform distribution
pconfint <- apply(apply(matrix(runif(10000 * n), nrow = n), 2, sort), 1, quantile, probs = c(0.025, 0.975))
lines((1:n)/(n+1), pconfint[1,], lty = 2, col = 2)
lines((1:n)/(n+1), pconfint[2,], lty = 2, col = 2)

```


## Poisson model for contingency table

We analyze a $4 \times 3$ contingency table containing information about tumour type.
The first factor is cancer `type`, with levels

1. Hutchinson's melanotic freckle, 
2. Superficial spreading melanoma, 
3. Nodular
4. for Indeterminate type

The second variable, `site`, is one of 
1. Head and Neck, 
2. Trunk,
3. Extremities

The data are count, hence we proceed with the analysis using a Poisson likelihood. This ressembles ANOVA models with factors.

```{r poissonexample }
# Create dataset
site <- gl(n = 3, k = 1, length = 12) 
# gl generates levels of a factor
tumor <- gl(n = 4, k = 3) #each 3
cases <- c(22, 2, 10, 16, 54, 115, 19, 33, 73, 11, 17, 28)
cancer <- data.frame(tumor, site, cases)
# Four cases - no effect, main interaction only, additive
cancer.m0 <- glm(cases ~ 1, family = poisson, data = cancer)
cancer.m1 <- glm(cases ~ tumor, family = poisson, data = cancer)
cancer.m2 <- glm(cases ~ site, family = poisson, data = cancer)
cancer.m3 <- glm(cases ~ tumor + site, family = poisson, data = cancer)
# Saturated model
cancer.m4 <- glm(cases ~ tumor * site, family = poisson, data = cancer)
# Analysis of deviance
# Same syntax as for GLM
drop1(cancer.m4)
anova(cancer.m3, cancer.m4, test = "Chisq")
# anova(cancer.m4) returns three tests, 
# but only the comparison with additive model is justified
summary(cancer.m4)
# Alternatively, compute manually
1 - pchisq(deviance(cancer.m3), df = cancer.m3$df.residual)
```

The likelihood ratio test to check whether the interaction is significative is soundly rejected, hence we would keep the saturated model. For such a model, the fitted values correspond to the observed counts. 

This is an example where the hypothesis of equal mean and variance does not seem to hold. Handling the overdispersion is beyond the scope of this course.


